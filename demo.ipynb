{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import nntools as nt\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "from models import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/datasets/ee285f-public/VQA2017/'\n",
    "q_dir = '/datasets/ee285f-public/VQA2017/v2_OpenEnded_mscoco_'\n",
    "ans_dir = '/datasets/ee285f-public/VQA2017/v2_mscoco_'\n",
    "\n",
    "train_set = MSCOCODataset(images_dir, q_dir, \n",
    "                          ans_dir, mode='train', \n",
    "                          image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentLoader():\n",
    "    def __init__(self, input_dir, train_set, batch_size, lr=0.01, weight_decay=0.5):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        self.inv_q = {v: k for k, v in self.train_set.vocab_q.items()} \n",
    "        self.inv_a = {v: k for k, v in self.train_set.vocab_a.items()} \n",
    "        \n",
    "        self.model = SAN(num_classes=1000, batch_size=batch_size, \n",
    "                         vocab_size=len(self.train_set.vocab_q), embedding_dim=500,\n",
    "                         output_vgg=1024, input_attention=1024, output_attention=512).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                         lr=lr, \n",
    "                                         weight_decay=weight_decay)\n",
    "        self.batch_size = None\n",
    "        self.history = None\n",
    "        self.train_loss = None\n",
    "        self.train_acc = None\n",
    "        self.indices = None\n",
    "        \n",
    "        os.makedirs(input_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(input_dir, \n",
    "                                       \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(input_dir, \"config.txt\")\n",
    "        \n",
    "        # Transfer all local arguments/variables into attributes\n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            self.load()\n",
    "    \n",
    "    def sample(self, idx):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            entry = self.train_set[idx]\n",
    "\n",
    "            i, q, s, a = entry[0].to(self.device), entry[1].to(self.device), \\\n",
    "                         entry[2], entry[3].to(self.device)\n",
    "            \n",
    "            #myimshow(i)\n",
    "            \n",
    "            question = []\n",
    "            for index in range(s):\n",
    "                question.append(self.inv_q[int(entry[1][index])])\n",
    "\n",
    "            #print(\"Question:\", ' '.join(question))\n",
    "            \n",
    "            i = i.unsqueeze(dim=0)\n",
    "            q = q.unsqueeze(dim=0)\n",
    "            s = torch.Tensor([s])\n",
    "\n",
    "            predicted_answer = F.softmax(self.model.forward(i, q.long(), s.long()))\n",
    "            _, y_pred = torch.max(predicted_answer, 1)\n",
    "            \n",
    "            print(\"Answer:\", self.inv_a[int(y_pred)])            \n",
    "    \n",
    "    @property\n",
    "    def epoch(self):\n",
    "        return len(self.history)\n",
    "\n",
    "    def setting(self):\n",
    "        return {'Net': self.model,\n",
    "                'Train Set': self.train_set,\n",
    "                'Optimizer': self.optimizer,\n",
    "                'BatchSize': self.batch_size}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Pretty printer showing the setting of the experiment. This is what\n",
    "        is displayed when doing ``print(experiment)``. This is also what is\n",
    "        saved in the ``config.txt`` file.\n",
    "        \"\"\"\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'Net': self.model.state_dict(),\n",
    "                'Optimizer': self.optimizer.state_dict(),\n",
    "                'History': self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainAcc' : self.train_acc,\n",
    "                'Indices' : self.indices}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        self.model.load_state_dict(checkpoint['Net'])\n",
    "        self.optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_acc = checkpoint['TrainAcc']\n",
    "        self.indices = checkpoint['Indices']\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(self.device)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentLoader(train_set=train_set, batch_size=250, input_dir=\"newexp_batch250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = exp.indices\n",
    "\n",
    "ind = indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "exp.sample(1214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
