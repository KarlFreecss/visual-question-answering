{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%run models.ipynb\n",
    "%run preprocess.ipynb\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.utils.data as td \n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import nntools as nt\n",
    "import PIL\n",
    "import math\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, epochs, B=100, gamma=0.01, rho=0.9):\n",
    "    model.train()\n",
    "    \n",
    "    N = len(data) # size of data\n",
    "    NB = int((N+B-1)/B) # number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=gamma, momentum=rho)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        running_loss = 0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        \n",
    "        for k in range(NB):\n",
    "            # extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            \n",
    "            return minibatch_indices\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, q, a = None, None, None\n",
    "\n",
    "for a, b, c in train_loader:\n",
    "    i = a\n",
    "    q = b\n",
    "    a = c\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i.cuda()\n",
    "q = q.cuda()\n",
    "a = a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %run models.ipynb\n",
    "\n",
    "# vgg = VGGNet(output_features=1024)\n",
    "# vgg = vgg.cuda()\n",
    "\n",
    "# out_vgg = vgg(i)\n",
    "\n",
    "# lstm = LSTM(len(train.vocab_q), embedding_dim=1000, batch_size=10)\n",
    "# lstm = lstm.cuda()\n",
    "\n",
    "# out_lstm = lstm(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pI = torch.rand(10,196,1)\n",
    "# vI = torch.rand(10,196,1024)\n",
    "# torch.matmul(vI.view(10, 1024,196),pI).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = AttentionNet(100,batch_size=10,input_features=1024,output_features=512,image_features=196).to('cuda')\n",
    "# x = net(out_lstm.to('cuda'), out_vgg.to('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb\n",
    "\n",
    "san = SAN(num_classes=1000, batch_size=10, vocab_size=len(train.vocab_q), embedding_dim=1000,\n",
    "          output_vgg=1024, input_attention=1024, output_attention=512)\n",
    "\n",
    "san = san.cuda()\n",
    "\n",
    "output = san(i, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-73d339b173b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[0;34m(dataset, lengths)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0mof\u001b[0m \u001b[0msplits\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mproduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "torch.utils.data.random_split(train, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnge1 = list(range(int(len(train) * 0.8)))\n",
    "rnge2 = list(range(rnge1[-1]+1, len(train)))\n",
    "\n",
    "t_ind = torch.utils.data.sampler.SubsetRandomSampler(rnge1)\n",
    "v_ind = torch.utils.data.sampler.SubsetRandomSampler(rnge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=10, pin_memory=True, sampler=t_ind)\n",
    "val_loader = torch.utils.data.DataLoader(train, batch_size=10, pin_memory=True, sampler=v_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
