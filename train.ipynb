{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import nntools as nt\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "from models import *\n",
    "from preprocess import *\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100\n"
     ]
    }
   ],
   "source": [
    "images_dir = '/datasets/ee285f-public/VQA2017/'\n",
    "q_dir = '/datasets/ee285f-public/VQA2017/v2_OpenEnded_mscoco_'\n",
    "ans_dir = '/datasets/ee285f-public/VQA2017/v2_mscoco_'\n",
    "\n",
    "train_set = MSCOCODataset(images_dir, q_dir, \n",
    "                          ans_dir, mode='train', \n",
    "                          image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x : x[2], reverse=True)\n",
    "    return data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANExperiment():\n",
    "    def __init__(self, train_set, output_dir, batch_size=200, num_epochs=1):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        self.indices = np.random.permutation(len(self.train_set))\n",
    "        self.indices = self.indices[:int(len(self.indices)*0.5)]\n",
    "                \n",
    "        train_ind = self.indices[:int(len(self.indices)*0.8)]\n",
    "        val_ind = self.indices[int(len(self.indices)*0.8):]\n",
    "        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\n",
    "        val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_ind)\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                        sampler=train_sampler,\n",
    "                                                        collate_fn=collate_fn)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                      sampler=val_sampler,\n",
    "                                                      collate_fn=collate_fn)\n",
    "        \n",
    "        \n",
    "        self.image_model = VGGNet(output_features=1024).to(self.device)\n",
    "        self.question_model = LSTM(vocab_size=len(self.train_set.vocab_q), embedding_dim=1000,\n",
    "                                   batch_size=batch_size, hidden_dim=1024).to(self.device)\n",
    "        self.attention = AttentionNet(num_classes=1000, batch_size=batch_size,\n",
    "                                      input_features=1024, output_features=512).to(self.device)\n",
    "        \n",
    "        self.optimizer_parameter_group = [{'params': self.question_model.parameters()}, \n",
    "                                          {'params': self.image_model.parameters()},\n",
    "                                          {'params': self.attention.parameters()}]\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.RMSprop(self.optimizer_parameter_group,\n",
    "                                             lr=4e-4, alpha=0.99, eps=1e-8, momentum=0.9)\n",
    "        \n",
    "        self.total_ex = len(train_ind)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.history = []\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(output_dir, \n",
    "                                       \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        # Transfer all local arguments/variables into attributes\n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                if f.read()[:-1] != repr(self):\n",
    "                    raise ValueError(\n",
    "                        \"Cannot create this experiment: \"\n",
    "                        \"I found a checkpoint conflicting with the current setting.\")\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "    \n",
    "    @property\n",
    "    def epoch(self):\n",
    "        return len(self.history)\n",
    "\n",
    "    def setting(self):\n",
    "        return {'ImageModel': self.image_model,\n",
    "                'QuestionModel' : self.question_model,\n",
    "                'AttentionModel' : self.attention,\n",
    "                'Train Set': self.train_set,\n",
    "                'Optimizer': self.optimizer,\n",
    "                'BatchSize': self.batch_size}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Pretty printer showing the setting of the experiment. This is what\n",
    "        is displayed when doing ``print(experiment)``. This is also what is\n",
    "        saved in the ``config.txt`` file.\n",
    "        \"\"\"\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'ImageModel': self.image_model.state_dict(),\n",
    "                'QuestionModel' : self.question_model.state_dict(),\n",
    "                'AttentionModel' : self.attention.state_dict(),\n",
    "                'Optimizer': self.optimizer.state_dict(),\n",
    "                'History': self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainAcc' : self.train_acc}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        self.image_model.load_state_dict(checkpoint['ImageModel'])\n",
    "        self.question_model.load_state_dict(checkpoint['QuestionModel'])\n",
    "        self.attention.load_state_dict(checkpoint['AttentionModel'])\n",
    "        self.optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_acc = checkpoint['TrainAcc']\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(self.device)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Saves the experiment on disk, i.e, create/update the last checkpoint.\"\"\"\n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.image_model.eval()\n",
    "        self.question_model.eval()\n",
    "        self.attention.eval()\n",
    "        \n",
    "        loader = self.val_loader\n",
    "        \n",
    "        loss, acc = 0.0, 0.0\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for i, q, s, a in loader:\n",
    "                if (self.device == 'cuda'):\n",
    "                    i, q, s, a = i.cuda(), q.cuda(), s.cuda(), a.cuda()\n",
    "\n",
    "                i, q, s, a = Variable(i), Variable(q), Variable(s), Variable(a, required_grad=False)\n",
    "                \n",
    "                image_embed = self.image_model(i)\n",
    "                question_embed = self.question_model(q.long(), s.long())\n",
    "                output = self.attention(image_embed, question_embed)\n",
    "                \n",
    "                _, y_pred = torch.max(output, 1)\n",
    "\n",
    "                loss += self.criterion(output, a.long().squeeze(dim=1)).item()\n",
    "                acc += torch.sum((y_pred == a.long()).data)\n",
    "        \n",
    "        loss = (float(loss) / float(len(self.val_ind)))\n",
    "        acc = (float(acc) / float(len(self.val_ind)))\n",
    "        \n",
    "        print(\"Validation Loss:\", loss)\n",
    "        print(\"Validation Accuracy:\", acc)\n",
    "            \n",
    "    \n",
    "    def run(self):\n",
    "        self.image_model.train()\n",
    "        self.question_model.train()\n",
    "        self.attention.train()\n",
    "        \n",
    "        loader = self.train_loader\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        print(\"Start/Continue training from epoch {}\".format(start_epoch))\n",
    "        for epoch in range(start_epoch, self.num_epochs):\n",
    "            running_loss, running_acc, num_updates = 0.0, 0.0, 0.0\n",
    "            \n",
    "            counter = 0\n",
    "            \n",
    "            for i, q, s, a in loader:                \n",
    "                if (self.device == 'cuda'):\n",
    "                    i, q, s, a = i.cuda(), q.cuda(), s.cuda(), a.cuda()\n",
    "                        \n",
    "                i, q, s, a = Variable(i), Variable(q), Variable(s), Variable(a)\n",
    "                                \n",
    "                self.optimizer.zero_grad()\n",
    "                                \n",
    "                image_embed = self.image_model(i)\n",
    "                question_embed = self.question_model(q.long(), s.long())\n",
    "                output = self.attention(image_embed, question_embed)\n",
    "                \n",
    "                _, y_pred = torch.max(output, 1)\n",
    "                                                \n",
    "                try:\n",
    "                    loss = self.criterion(output, a.long().squeeze(dim=1))\n",
    "                except RuntimeError as e:\n",
    "                    if 'out of memory' in str(e):\n",
    "                        if hasattr(torch.cuda, 'emtpy_cache'):\n",
    "                            torch.cuda.empty_cache()\n",
    "                    else:\n",
    "                        raise e\n",
    "                        \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                    running_acc += torch.sum((y_pred == a.long()).data)\n",
    "                    \n",
    "                num_updates += 1\n",
    "                \n",
    "                print(\"Epoch: {}, Batch: {}, Loss = {}, Acc = {}\".format(epoch, counter, \n",
    "                                                              (float(running_loss) / float(num_updates * self.batch_size)),\n",
    "                                                              (float(running_acc) / float(num_updates * self.batch_size))))\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                self.save()\n",
    "                \n",
    "                counter += 1\n",
    "            \n",
    "            loss = (float(running_loss) / float(self.total_ex))\n",
    "            acc = (float(running_acc) / float(self.total_ex))\n",
    "            \n",
    "            print(\"Done with Epoch {}. Loss={}, Acc={}\".format(epoch, loss, acc))\n",
    "            \n",
    "            self.history.append(epoch)\n",
    "            self.train_loss.append(loss)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            self.save()\n",
    "        \n",
    "        print(\"Finish training for {} epochs\".format(self.num_epochs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = SANExperiment(output_dir=\"exp_batch200\", train_set=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Continue training from epoch 0\n",
      "Epoch: 0, Batch: 0, Loss = 0.03457996845245361, Acc = 0.08\n",
      "Epoch: 0, Batch: 1, Loss = 0.03449655175209045, Acc = 23.0975\n",
      "Epoch: 0, Batch: 2, Loss = 0.03277699232101441, Acc = 25.731666666666666\n",
      "Epoch: 0, Batch: 3, Loss = 0.03277163565158844, Acc = 21.02\n",
      "Epoch: 0, Batch: 4, Loss = 0.033548712253570555, Acc = 18.115\n",
      "Epoch: 0, Batch: 5, Loss = 0.03378322720527649, Acc = 20.223333333333333\n",
      "Epoch: 0, Batch: 6, Loss = 0.03351818697793143, Acc = 21.675\n",
      "Epoch: 0, Batch: 7, Loss = 0.03295288920402527, Acc = 24.23\n",
      "Epoch: 0, Batch: 8, Loss = 0.03239020850923326, Acc = 25.789444444444445\n",
      "Epoch: 0, Batch: 9, Loss = 0.03212104606628418, Acc = 25.095\n",
      "Epoch: 0, Batch: 10, Loss = 0.031185008612546052, Acc = 25.565454545454546\n",
      "Epoch: 0, Batch: 11, Loss = 0.030570388038953147, Acc = 25.509166666666665\n",
      "Epoch: 0, Batch: 12, Loss = 0.02994707382642306, Acc = 25.330384615384617\n",
      "Epoch: 0, Batch: 13, Loss = 0.029471765586308072, Acc = 25.009642857142858\n",
      "Epoch: 0, Batch: 14, Loss = 0.029051708380381267, Acc = 24.739\n",
      "Epoch: 0, Batch: 15, Loss = 0.028731899112463, Acc = 24.611875\n",
      "Epoch: 0, Batch: 16, Loss = 0.028528485438402962, Acc = 24.13735294117647\n",
      "Epoch: 0, Batch: 17, Loss = 0.028200887044270834, Acc = 24.123333333333335\n",
      "Epoch: 0, Batch: 18, Loss = 0.02802931785583496, Acc = 23.938947368421054\n",
      "Epoch: 0, Batch: 19, Loss = 0.027725555181503297, Acc = 24.08625\n",
      "Epoch: 0, Batch: 20, Loss = 0.027493197804405577, Acc = 23.99738095238095\n",
      "Epoch: 0, Batch: 21, Loss = 0.027273643667047674, Acc = 23.76\n",
      "Epoch: 0, Batch: 22, Loss = 0.027002757321233334, Acc = 23.753260869565217\n",
      "Epoch: 0, Batch: 23, Loss = 0.026868002613385518, Acc = 23.506875\n",
      "Epoch: 0, Batch: 24, Loss = 0.02665650691986084, Acc = 23.5938\n",
      "Epoch: 0, Batch: 25, Loss = 0.026429503697615403, Acc = 23.555384615384614\n",
      "Epoch: 0, Batch: 26, Loss = 0.02619291137765955, Acc = 23.484444444444446\n",
      "Epoch: 0, Batch: 27, Loss = 0.02597461291721889, Acc = 23.506607142857142\n",
      "Epoch: 0, Batch: 28, Loss = 0.02570191588895074, Acc = 23.553103448275863\n",
      "Epoch: 0, Batch: 29, Loss = 0.025569785038630166, Acc = 23.49416666666667\n",
      "Epoch: 0, Batch: 30, Loss = 0.025441021996159708, Acc = 23.465\n",
      "Epoch: 0, Batch: 31, Loss = 0.02532696932554245, Acc = 23.3203125\n",
      "Epoch: 0, Batch: 32, Loss = 0.02523954673246904, Acc = 23.268030303030304\n",
      "Epoch: 0, Batch: 33, Loss = 0.02516534868408652, Acc = 23.13705882352941\n",
      "Epoch: 0, Batch: 34, Loss = 0.024981616156441826, Acc = 23.070714285714285\n",
      "Epoch: 0, Batch: 35, Loss = 0.024879552523295084, Acc = 22.963472222222222\n",
      "Epoch: 0, Batch: 36, Loss = 0.024752107053189663, Acc = 23.055945945945947\n",
      "Epoch: 0, Batch: 37, Loss = 0.024677604750583046, Acc = 22.992763157894736\n",
      "Epoch: 0, Batch: 38, Loss = 0.02454324939312079, Acc = 23.022179487179486\n",
      "Epoch: 0, Batch: 39, Loss = 0.024475496739149092, Acc = 22.932375\n",
      "Epoch: 0, Batch: 40, Loss = 0.02441384591707369, Acc = 22.869146341463416\n",
      "Epoch: 0, Batch: 41, Loss = 0.024304769464901517, Acc = 22.875\n",
      "Epoch: 0, Batch: 42, Loss = 0.02425423830054527, Acc = 22.80732558139535\n",
      "Epoch: 0, Batch: 43, Loss = 0.02425912220369686, Acc = 22.689886363636365\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a33583383f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-050634996c34>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mimage_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mquestion_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/49/249/abiyer/visual-question-answering/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q_ind, seq_length)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first)\u001b[0m\n\u001b[1;32m    145\u001b[0m                       \u001b[0;34m'the trace incorrect for any other combination of lengths.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                       category=torch.jit.TracerWarning, stacklevel=2)\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(exp.question_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
