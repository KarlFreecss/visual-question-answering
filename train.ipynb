{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import nntools as nt\n",
    "import torch\n",
    "\n",
    "from models import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/datasets/ee285f-public/VQA2017/'\n",
    "q_dir = '/datasets/ee285f-public/VQA2017/v2_OpenEnded_mscoco_'\n",
    "ans_dir = '/datasets/ee285f-public/VQA2017/v2_mscoco_'\n",
    "\n",
    "train_set = MSCOCODataset(images_dir, q_dir, \n",
    "                          ans_dir, mode='train', \n",
    "                          image_size=(448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANExperiment():\n",
    "    def __init__(self, train_set, output_dir, batch_size=10,\n",
    "                 perform_validation_during_training=False,\n",
    "                 lr=0.01, weight_decay=0.5,\n",
    "                 num_epochs=1):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        \n",
    "        indices = np.random.permutation(int(len(self.train_set) * 0.013))\n",
    "                \n",
    "        train_ind = indices[:int(len(indices)*0.8)]\n",
    "        val_ind = indices[int(len(indices)*0.8):]\n",
    "        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\n",
    "        val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_ind)\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                        pin_memory=True, \n",
    "                                                        sampler=train_sampler)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                      pin_memory=True, \n",
    "                                                      sampler=val_sampler)\n",
    "        \n",
    "        self.model = SAN(num_classes=1000, batch_size=batch_size, \n",
    "                         vocab_size=len(self.train_set.vocab_q), embedding_dim=1000,\n",
    "                         output_vgg=1024, input_attention=1024, output_attention=512).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                          lr=lr, \n",
    "                                          weight_decay=weight_decay)\n",
    "        \n",
    "        self.total_ex = len(train_ind)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.history = []\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(output_dir, \n",
    "                                       \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        # Transfer all local arguments/variables into attributes\n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                if f.read()[:-1] != repr(self):\n",
    "                    raise ValueError(\n",
    "                        \"Cannot create this experiment: \"\n",
    "                        \"I found a checkpoint conflicting with the current setting.\")\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "    \n",
    "    @property\n",
    "    def epoch(self):\n",
    "        return len(self.history)\n",
    "\n",
    "    def setting(self):\n",
    "        return {'Net': self.model,\n",
    "                'Train Set': self.train_set,\n",
    "                'Optimizer': self.optimizer,\n",
    "                'BatchSize': self.batch_size}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Pretty printer showing the setting of the experiment. This is what\n",
    "        is displayed when doing ``print(experiment)``. This is also what is\n",
    "        saved in the ``config.txt`` file.\n",
    "        \"\"\"\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'Net': self.model.state_dict(),\n",
    "                'Optimizer': self.optimizer.state_dict(),\n",
    "                'History': self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainAcc' : self.train_acc}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        self.model.load_state_dict(checkpoint['Net'])\n",
    "        self.optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_acc = checkpoint['TrainAcc']\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(self.device)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Saves the experiment on disk, i.e, create/update the last checkpoint.\"\"\"\n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "    \n",
    "    def run(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        loader = self.train_loader\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        print(\"Start/Continue training from epoch {}\".format(start_epoch))\n",
    "        for epoch in range(start_epoch, self.num_epochs):\n",
    "            running_loss, running_acc, num_updates = 0.0, 0.0, 0.0\n",
    "            \n",
    "            for i, q, a in loader:                \n",
    "                if (self.device == 'cuda'):\n",
    "                    i, q, a = i.cuda(), q.cuda(), a.cuda()\n",
    "                \n",
    "                i, q, a = Variable(i), Variable(q), Variable(a)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                predicted_answer = self.model.forward(i, q)\n",
    "                \n",
    "                _, class_ind = torch.max(a, 1)\n",
    "                _, y_pred = torch.max(predicted_answer, 1)\n",
    "                \n",
    "                loss = self.criterion(predicted_answer, class_ind)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                    running_acc += torch.sum((y_pred == class_ind).data)\n",
    "                        \n",
    "                num_updates += 1\n",
    "                \n",
    "                print(\"Epoch: {}, Loss = {}\".format(epoch, (float(running_loss) / float(num_updates * self.batch_size))))\n",
    "                \n",
    "            loss = (float(running_loss) / float(self.total_ex))\n",
    "            acc = (float(running_acc) / float(self.total_ex)) * 100\n",
    "            \n",
    "            print(\"Done with Epoch {}. Loss={}, Acc={}\".format(epoch, loss, acc))\n",
    "            \n",
    "            self.history.append(epoch)\n",
    "            self.train_loss.append(loss)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            self.save()\n",
    "        \n",
    "        print(\"Finish training for {} epochs\".format(self.num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = SANExperiment(output_dir=\"exp\", train_set=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
