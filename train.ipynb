{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import nntools as nt\n",
    "import torch\n",
    "\n",
    "from models import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/datasets/ee285f-public/VQA2017/'\n",
    "q_dir = '/datasets/ee285f-public/VQA2017/v2_OpenEnded_mscoco_'\n",
    "ans_dir = '/datasets/ee285f-public/VQA2017/v2_mscoco_'\n",
    "\n",
    "train_set = MSCOCODataset(images_dir, q_dir, \n",
    "                          ans_dir, mode='train', \n",
    "                          image_size=(448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANExperiment():\n",
    "    def __init__(self, train_set, output_dir, batch_size=10,\n",
    "                 perform_validation_during_training=False,\n",
    "                 lr=0.01, weight_decay=0.5,\n",
    "                 num_epochs=3):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        \n",
    "        indices = np.random.permutation(int(len(self.train_set) * 0.013))\n",
    "        train_ind = indices[:int(len(indices)*0.8)]\n",
    "        val_ind = indices[int(len(indices)*0.8):]\n",
    "        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\n",
    "        val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_ind)\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                        pin_memory=True, \n",
    "                                                        sampler=train_sampler)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.train_set, batch_size=batch_size, \n",
    "                                                      pin_memory=True, \n",
    "                                                      sampler=val_sampler)\n",
    "        \n",
    "        self.model = SAN(num_classes=1000, batch_size=batch_size, \n",
    "                         vocab_size=len(self.train_set.vocab_q), embedding_dim=1000,\n",
    "                         output_vgg=1024, input_attention=1024, output_attention=512).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                          lr=lr, \n",
    "                                          weight_decay=weight_decay)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.history = []\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(output_dir, \n",
    "                                       \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        # Transfer all local arguments/variables into attributes\n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                if f.read()[:-1] != repr(self):\n",
    "                    raise ValueError(\n",
    "                        \"Cannot create this experiment: \"\n",
    "                        \"I found a checkpoint conflicting with the current setting.\")\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "    \n",
    "    @property\n",
    "    def epoch(self):\n",
    "        return len(self.history)\n",
    "\n",
    "    def setting(self):\n",
    "        return {'Net': self.model,\n",
    "                'Train Set': self.train_set,\n",
    "                'Optimizer': self.optimizer,\n",
    "                'BatchSize': self.batch_size}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Pretty printer showing the setting of the experiment. This is what\n",
    "        is displayed when doing ``print(experiment)``. This is also what is\n",
    "        saved in the ``config.txt`` file.\n",
    "        \"\"\"\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'Net': self.model.state_dict(),\n",
    "                'Optimizer': self.optimizer.state_dict(),\n",
    "                'History': self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainAcc' : self.train_acc}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        self.model.load_state_dict(checkpoint['Net'])\n",
    "        self.optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_acc = checkpoint['TrainAcc']\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(self.device)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Saves the experiment on disk, i.e, create/update the last checkpoint.\"\"\"\n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "    \n",
    "    def run(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        loader = self.train_loader\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        print(\"Start/Continue training from epoch {}\".format(start_epoch))\n",
    "        for epoch in range(start_epoch, self.num_epochs):\n",
    "            running_loss, running_acc, num_updates = 0.0, 0.0, 0.0\n",
    "            \n",
    "            for i, q, a in loader:                \n",
    "                if (self.device == 'cuda'):\n",
    "                    i, q, a = i.cuda(), q.cuda(), a.cuda()\n",
    "                \n",
    "                i, q, a = Variable(i), Variable(q), Variable(a)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                predicted_answer = self.model.forward(i, q)\n",
    "                \n",
    "                _, class_ind = torch.max(a, 1)\n",
    "                _, y_pred = torch.max(predicted_answer, 1)\n",
    "                \n",
    "                loss = self.criterion(predicted_answer, class_ind)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                    running_acc += torch.sum((y_pred == class_ind).data)\n",
    "                num_updates += 1\n",
    "                \n",
    "                print(\"Epoch: {}, Loss = {}\".format(epoch, running_loss/(num_updates*self.batch_size)))\n",
    "                \n",
    "            loss = (running_loss / len(loader.dataset))\n",
    "            print(\"Loss after Epoch {}: {}\".format(epoch, loss))\n",
    "            acc = (running_acc / len(loader.dataset)) * 100\n",
    "            \n",
    "            self.history.append(epoch)\n",
    "            self.train_loss.append(loss)\n",
    "            self.train_acc.append(acc)\n",
    "            \n",
    "            self.save()\n",
    "        \n",
    "        print(\"Finish training for {} epochs\".format(self.num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = SANExperiment(output_dir=\"exp\", train_set=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Continue training from epoch 0\n",
      "Epoch: 0, Loss = 0.6907885551452637\n",
      "Epoch: 0, Loss = 0.6907859325408936\n",
      "Epoch: 0, Loss = 0.6907823403676351\n",
      "Epoch: 0, Loss = 0.6907804846763611\n",
      "Epoch: 0, Loss = 0.6907794284820556\n",
      "Epoch: 0, Loss = 0.6907788435618083\n",
      "Epoch: 0, Loss = 0.6907783576420375\n",
      "Epoch: 0, Loss = 0.6907779276371002\n",
      "Epoch: 0, Loss = 0.6907777521345351\n",
      "Epoch: 0, Loss = 0.6907775211334228\n",
      "Epoch: 0, Loss = 0.6907773321325129\n",
      "Epoch: 0, Loss = 0.690777309735616\n",
      "Epoch: 0, Loss = 0.6907772357647236\n",
      "Epoch: 0, Loss = 0.6907771417072841\n",
      "Epoch: 0, Loss = 0.690777063369751\n",
      "Epoch: 0, Loss = 0.6907769948244095\n",
      "Epoch: 0, Loss = 0.6907769119038302\n",
      "Epoch: 0, Loss = 0.6907768434948391\n",
      "Epoch: 0, Loss = 0.6907767546804328\n",
      "Epoch: 0, Loss = 0.6907766819000244\n",
      "Epoch: 0, Loss = 0.6907766092391241\n",
      "Epoch: 0, Loss = 0.6907765431837602\n",
      "Epoch: 0, Loss = 0.6907764932383662\n",
      "Epoch: 0, Loss = 0.6907764434814453\n",
      "Epoch: 0, Loss = 0.6907764091491699\n",
      "Epoch: 0, Loss = 0.690776381125817\n",
      "Epoch: 0, Loss = 0.6907763640085857\n",
      "Epoch: 0, Loss = 0.6907763395990644\n",
      "Epoch: 0, Loss = 0.6907763168729585\n",
      "Epoch: 0, Loss = 0.6907762924830119\n",
      "Epoch: 0, Loss = 0.6907762650520571\n",
      "Epoch: 0, Loss = 0.690776239335537\n",
      "Epoch: 0, Loss = 0.6907762151775938\n",
      "Epoch: 0, Loss = 0.6907761924407061\n",
      "Epoch: 0, Loss = 0.6907761737278529\n",
      "Epoch: 0, Loss = 0.6907761560546027\n",
      "Epoch: 0, Loss = 0.6907761367591652\n",
      "Epoch: 0, Loss = 0.690776118479277\n",
      "Epoch: 0, Loss = 0.6907761011368189\n",
      "Epoch: 0, Loss = 0.6907760882377625\n",
      "Epoch: 0, Loss = 0.6907760748049108\n",
      "Epoch: 0, Loss = 0.6907760631470453\n",
      "Epoch: 0, Loss = 0.6907760487046353\n",
      "Epoch: 0, Loss = 0.6907760381698609\n",
      "Epoch: 0, Loss = 0.6907760270436605\n",
      "Epoch: 0, Loss = 0.6907760174378105\n",
      "Epoch: 0, Loss = 0.6907760051970786\n",
      "Epoch: 0, Loss = 0.6907759954531988\n",
      "Epoch: 0, Loss = 0.6907759841607541\n",
      "Epoch: 0, Loss = 0.6907759733200073\n",
      "Epoch: 0, Loss = 0.6907759629043878\n",
      "Epoch: 0, Loss = 0.6907759547233582\n",
      "Epoch: 0, Loss = 0.6907759468510466\n",
      "Epoch: 0, Loss = 0.6907759392703021\n",
      "Epoch: 0, Loss = 0.690775931965221\n",
      "Epoch: 0, Loss = 0.6907759249210358\n",
      "Epoch: 0, Loss = 0.6907759164509021\n",
      "Epoch: 0, Loss = 0.6907759082728419\n",
      "Epoch: 0, Loss = 0.6907759019884012\n",
      "Epoch: 0, Loss = 0.6907758943239848\n",
      "Epoch: 0, Loss = 0.6907758884742612\n",
      "Epoch: 0, Loss = 0.6907758828132383\n",
      "Epoch: 0, Loss = 0.6907758780888149\n",
      "Epoch: 0, Loss = 0.6907758727669716\n",
      "Epoch: 0, Loss = 0.6907758676088773\n",
      "Epoch: 0, Loss = 0.6907758611621279\n",
      "Epoch: 0, Loss = 0.6907758570429104\n",
      "Epoch: 0, Loss = 0.6907758523436154\n",
      "Epoch: 0, Loss = 0.6907758484716001\n",
      "Epoch: 0, Loss = 0.6907758447102138\n",
      "Epoch: 0, Loss = 0.6907758410547821\n",
      "Epoch: 0, Loss = 0.6907758375008901\n",
      "Epoch: 0, Loss = 0.6907758320847602\n",
      "Epoch: 0, Loss = 0.6907758281037614\n",
      "Epoch: 0, Loss = 0.6907758229573567\n",
      "Epoch: 0, Loss = 0.6907758173189665\n",
      "Epoch: 0, Loss = 0.6907758136848351\n",
      "Epoch: 0, Loss = 0.6907758101438864\n",
      "Epoch: 0, Loss = 0.6907758072961735\n",
      "Epoch: 0, Loss = 0.6907758039236068\n",
      "Epoch: 0, Loss = 0.6907758012230014\n",
      "Epoch: 0, Loss = 0.6907757962622294\n",
      "Epoch: 0, Loss = 0.6907757931445019\n",
      "Epoch: 0, Loss = 0.6907757889656794\n",
      "Epoch: 0, Loss = 0.6907757860071518\n",
      "Epoch: 0, Loss = 0.6907757836718892\n",
      "Epoch: 0, Loss = 0.690775780842222\n",
      "Epoch: 0, Loss = 0.6907757769931446\n",
      "Epoch: 0, Loss = 0.6907757726947913\n",
      "Epoch: 0, Loss = 0.6907757684919569\n",
      "Epoch: 0, Loss = 0.6907757643814926\n",
      "Epoch: 0, Loss = 0.690775760360386\n",
      "Epoch: 0, Loss = 0.6907757579639394\n",
      "Epoch: 0, Loss = 0.6907757561257545\n",
      "Epoch: 0, Loss = 0.6907757543262683\n",
      "Epoch: 0, Loss = 0.6907757525642713\n",
      "Epoch: 0, Loss = 0.6907757508386042\n",
      "Epoch: 0, Loss = 0.6907757472018806\n",
      "Epoch: 0, Loss = 0.6907757436386263\n",
      "Epoch: 0, Loss = 0.6907757415771484\n",
      "Epoch: 0, Loss = 0.6907757381401439\n",
      "Epoch: 0, Loss = 0.6907757366404814\n",
      "Epoch: 0, Loss = 0.6907757347069897\n",
      "Epoch: 0, Loss = 0.6907757314351889\n",
      "Epoch: 0, Loss = 0.6907757295880999\n",
      "Epoch: 0, Loss = 0.6907757277758616\n",
      "Epoch: 0, Loss = 0.6907757264431392\n",
      "Epoch: 0, Loss = 0.6907757251350968\n",
      "Epoch: 0, Loss = 0.6907757225386594\n",
      "Epoch: 0, Loss = 0.6907757212898948\n",
      "Epoch: 0, Loss = 0.6907757196340475\n",
      "Epoch: 0, Loss = 0.6907757184335164\n",
      "Epoch: 0, Loss = 0.6907757172542336\n",
      "Epoch: 0, Loss = 0.6907757160956399\n",
      "Epoch: 0, Loss = 0.6907757149571958\n",
      "Epoch: 0, Loss = 0.69077571383838\n",
      "Epoch: 0, Loss = 0.6907757127386892\n",
      "Epoch: 0, Loss = 0.690775711253538\n",
      "Epoch: 0, Loss = 0.6907757101940508\n",
      "Epoch: 0, Loss = 0.6907757075627645\n",
      "Epoch: 0, Loss = 0.6907757049749705\n",
      "Epoch: 0, Loss = 0.6907757024295994\n",
      "Epoch: 0, Loss = 0.6907756999256165\n",
      "Epoch: 0, Loss = 0.6907756978465664\n",
      "Epoch: 0, Loss = 0.6907756965637207\n",
      "Epoch: 0, Loss = 0.6907756956796798\n",
      "Epoch: 0, Loss = 0.6907756948095607\n",
      "Epoch: 0, Loss = 0.6907756939530373\n",
      "Epoch: 0, Loss = 0.6907756931097933\n",
      "Epoch: 0, Loss = 0.6907756922795223\n",
      "Epoch: 0, Loss = 0.6907756914619271\n",
      "Epoch: 0, Loss = 0.6907756892117587\n",
      "Epoch: 0, Loss = 0.6907756873539516\n",
      "Epoch: 0, Loss = 0.6907756862355702\n",
      "Epoch: 0, Loss = 0.690775684427332\n",
      "Epoch: 0, Loss = 0.6907756836975322\n",
      "Epoch: 0, Loss = 0.6907756829783864\n",
      "Epoch: 0, Loss = 0.690775682269663\n",
      "Epoch: 0, Loss = 0.6907756812280889\n",
      "Epoch: 0, Loss = 0.6907756805419922\n",
      "Epoch: 0, Loss = 0.6907756798656274\n",
      "Epoch: 0, Loss = 0.6907756791987889\n",
      "Epoch: 0, Loss = 0.6907756785412769\n",
      "Epoch: 0, Loss = 0.6907756778928968\n",
      "Epoch: 0, Loss = 0.69077567725346\n",
      "Epoch: 0, Loss = 0.6907756762961819\n",
      "Epoch: 0, Loss = 0.6907756756763069\n",
      "Epoch: 0, Loss = 0.6907756750648086\n",
      "Epoch: 0, Loss = 0.6907756744615183\n",
      "Epoch: 0, Loss = 0.6907756738662719\n",
      "Epoch: 0, Loss = 0.6907756732789097\n",
      "Epoch: 0, Loss = 0.6907756726992758\n",
      "Epoch: 0, Loss = 0.6907756721272188\n",
      "Epoch: 0, Loss = 0.6907756703240531\n",
      "Epoch: 0, Loss = 0.6907756694670646\n",
      "Epoch: 0, Loss = 0.690775668926728\n",
      "Epoch: 0, Loss = 0.6907756683932748\n",
      "Epoch: 0, Loss = 0.6907756678665741\n",
      "Epoch: 0, Loss = 0.6907756673464985\n",
      "Epoch: 0, Loss = 0.6907756668329239\n",
      "Epoch: 0, Loss = 0.690775666029557\n",
      "Epoch: 0, Loss = 0.690775665530452\n",
      "Epoch: 0, Loss = 0.6907756650374711\n",
      "Epoch: 0, Loss = 0.6907756645505021\n",
      "Epoch: 0, Loss = 0.6907756640694358\n",
      "Epoch: 0, Loss = 0.6907756635941655\n",
      "Epoch: 0, Loss = 0.690775663124587\n",
      "Epoch: 0, Loss = 0.6907756626605988\n",
      "Epoch: 0, Loss = 0.6907756622021015\n",
      "Epoch: 0, Loss = 0.690775660907521\n",
      "Epoch: 0, Loss = 0.6907756604646381\n",
      "Epoch: 0, Loss = 0.6907756600269052\n",
      "Epoch: 0, Loss = 0.6907756595942326\n",
      "Epoch: 0, Loss = 0.6907756591665334\n",
      "Epoch: 0, Loss = 0.6907756576538086\n",
      "Epoch: 0, Loss = 0.6907756561582739\n",
      "Epoch: 0, Loss = 0.6907756554878364\n",
      "Epoch: 0, Loss = 0.690775655092818\n",
      "Epoch: 0, Loss = 0.6907756547022132\n",
      "Epoch: 0, Loss = 0.6907756543159485\n",
      "Epoch: 0, Loss = 0.6907756528801681\n",
      "Epoch: 0, Loss = 0.6907756514601655\n",
      "Epoch: 0, Loss = 0.6907756508373823\n",
      "Epoch: 0, Loss = 0.6907756504805191\n",
      "Epoch: 0, Loss = 0.690775650127514\n",
      "Epoch: 0, Loss = 0.6907756490092124\n",
      "Epoch: 0, Loss = 0.690775647647878\n",
      "Epoch: 0, Loss = 0.6907756463010261\n",
      "Epoch: 0, Loss = 0.6907756459776055\n",
      "Epoch: 0, Loss = 0.6907756456575895\n",
      "Epoch: 0, Loss = 0.6907756453409245\n",
      "Epoch: 0, Loss = 0.6907756447792053\n",
      "Epoch: 0, Loss = 0.6907756434821094\n",
      "Epoch: 0, Loss = 0.6907756421983856\n",
      "Epoch: 0, Loss = 0.6907756419059558\n",
      "Epoch: 0, Loss = 0.6907756416165098\n",
      "Epoch: 0, Loss = 0.6907756410879532\n",
      "Epoch: 0, Loss = 0.6907756408055623\n",
      "Epoch: 0, Loss = 0.6907756405260096\n",
      "Epoch: 0, Loss = 0.6907756400108337\n",
      "Epoch: 0, Loss = 0.6907756397380165\n",
      "Epoch: 0, Loss = 0.6907756394679003\n",
      "Epoch: 0, Loss = 0.6907756392004455\n",
      "Epoch: 0, Loss = 0.6907756389356127\n",
      "Epoch: 0, Loss = 0.6907756384407602\n",
      "Epoch: 0, Loss = 0.6907756381821863\n",
      "Epoch: 0, Loss = 0.6907756379261109\n",
      "Epoch: 0, Loss = 0.6907756376724977\n",
      "Epoch: 0, Loss = 0.6907756374213114\n",
      "Epoch: 0, Loss = 0.690775636945452\n",
      "Epoch: 0, Loss = 0.6907756357961357\n",
      "Epoch: 0, Loss = 0.6907756346576619\n",
      "Epoch: 0, Loss = 0.6907756344253468\n",
      "Epoch: 0, Loss = 0.6907756341952029\n",
      "Epoch: 0, Loss = 0.6907756339672\n",
      "Epoch: 0, Loss = 0.6907756328582764\n",
      "Epoch: 0, Loss = 0.6907756317595732\n",
      "Epoch: 0, Loss = 0.6907756315458805\n",
      "Epoch: 0, Loss = 0.6907756313341393\n",
      "Epoch: 0, Loss = 0.690775631124323\n",
      "Epoch: 0, Loss = 0.6907756300533519\n",
      "Epoch: 0, Loss = 0.6907756289920292\n",
      "Epoch: 0, Loss = 0.6907756285817099\n",
      "Epoch: 0, Loss = 0.690775628387928\n",
      "Epoch: 0, Loss = 0.6907756281958686\n",
      "Epoch: 0, Loss = 0.690775627794519\n",
      "Epoch: 0, Loss = 0.6907756267665242\n",
      "Epoch: 0, Loss = 0.6907756263749641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss = 0.6907756253621463\n",
      "Epoch: 0, Loss = 0.6907756251874178\n",
      "Epoch: 0, Loss = 0.6907756250142019\n",
      "Epoch: 0, Loss = 0.6907756248424793\n",
      "Epoch: 0, Loss = 0.6907756246722307\n",
      "Epoch: 0, Loss = 0.690775623688331\n",
      "Epoch: 0, Loss = 0.6907756235244427\n",
      "Epoch: 0, Loss = 0.6907756233619431\n",
      "Epoch: 0, Loss = 0.6907756229996178\n",
      "Epoch: 0, Loss = 0.690775622840689\n",
      "Epoch: 0, Loss = 0.6907756226830901\n",
      "Epoch: 0, Loss = 0.6907756225268046\n",
      "Epoch: 0, Loss = 0.6907756221739583\n",
      "Epoch: 0, Loss = 0.6907756220210682\n",
      "Epoch: 0, Loss = 0.6907756210845194\n",
      "Epoch: 0, Loss = 0.6907756209373475\n",
      "Epoch: 0, Loss = 0.6907756207913769\n",
      "Epoch: 0, Loss = 0.690775620646593\n",
      "Epoch: 0, Loss = 0.6907756205029816\n",
      "Epoch: 0, Loss = 0.6907756195914361\n",
      "Epoch: 0, Loss = 0.6907756186872123\n",
      "Epoch: 0, Loss = 0.6907756185531616\n",
      "Epoch: 0, Loss = 0.6907756184201791\n",
      "Epoch: 0, Loss = 0.6907756182882521\n",
      "Epoch: 0, Loss = 0.690775618157368\n",
      "Epoch: 0, Loss = 0.6907756172765896\n",
      "Epoch: 0, Loss = 0.6907756171506994\n",
      "Epoch: 0, Loss = 0.690775616839528\n",
      "Epoch: 0, Loss = 0.690775616716318\n",
      "Epoch: 0, Loss = 0.6907756160396014\n",
      "Epoch: 0, Loss = 0.6907756157363244\n",
      "Epoch: 0, Loss = 0.6907756154353802\n",
      "Epoch: 0, Loss = 0.6907756147713496\n",
      "Epoch: 0, Loss = 0.6907756146583849\n",
      "Epoch: 0, Loss = 0.690775614546279\n",
      "Epoch: 0, Loss = 0.6907756144350226\n",
      "Epoch: 0, Loss = 0.6907756143246057\n",
      "Epoch: 0, Loss = 0.6907756142150191\n",
      "Epoch: 0, Loss = 0.6907756139276626\n",
      "Epoch: 0, Loss = 0.6907756136424505\n",
      "Epoch: 0, Loss = 0.6907756128275705\n",
      "Epoch: 0, Loss = 0.6907756120187265\n",
      "Epoch: 0, Loss = 0.6907756119196705\n",
      "Epoch: 0, Loss = 0.690775611821343\n",
      "Epoch: 0, Loss = 0.6907756117237357\n",
      "Epoch: 0, Loss = 0.6907756116268409\n",
      "Epoch: 0, Loss = 0.6907756115306507\n",
      "Epoch: 0, Loss = 0.6907756114351576\n",
      "Epoch: 0, Loss = 0.690775611340354\n",
      "Epoch: 0, Loss = 0.6907756112462325\n",
      "Epoch: 0, Loss = 0.6907756111527856\n",
      "Epoch: 0, Loss = 0.6907756110600063\n",
      "Epoch: 0, Loss = 0.6907756109678872\n",
      "Epoch: 0, Loss = 0.6907756108764216\n",
      "Epoch: 0, Loss = 0.6907756107856022\n",
      "Epoch: 0, Loss = 0.6907756106954225\n",
      "Epoch: 0, Loss = 0.6907756106058757\n",
      "Epoch: 0, Loss = 0.6907756098500498\n",
      "Epoch: 0, Loss = 0.6907756090994911\n",
      "Epoch: 0, Loss = 0.69077560885085\n",
      "Epoch: 0, Loss = 0.6907756087689251\n",
      "Epoch: 0, Loss = 0.6907756086875653\n",
      "Epoch: 0, Loss = 0.6907756086067646\n",
      "Epoch: 0, Loss = 0.6907756078733157\n",
      "Epoch: 0, Loss = 0.6907756071448733\n",
      "Epoch: 0, Loss = 0.6907756069079548\n",
      "Epoch: 0, Loss = 0.6907756068342823\n",
      "Epoch: 0, Loss = 0.6907756067611076\n",
      "Epoch: 0, Loss = 0.6907756065278744\n",
      "Epoch: 0, Loss = 0.6907756062962065\n",
      "Epoch: 0, Loss = 0.6907756062255656\n",
      "Epoch: 0, Loss = 0.6907756061553955\n",
      "Epoch: 0, Loss = 0.6907756060856918\n",
      "Epoch: 0, Loss = 0.6907756058585565\n",
      "Epoch: 0, Loss = 0.6907756051608045\n",
      "Epoch: 0, Loss = 0.690775604467643\n",
      "Epoch: 0, Loss = 0.6907756042480468\n",
      "Epoch: 0, Loss = 0.6907756041857153\n",
      "Epoch: 0, Loss = 0.6907756041237897\n",
      "Epoch: 0, Loss = 0.6907756039074489\n",
      "Epoch: 0, Loss = 0.6907756036925085\n",
      "Epoch: 0, Loss = 0.6907756030174994\n",
      "Epoch: 0, Loss = 0.6907756029601265\n",
      "Epoch: 0, Loss = 0.6907756022917919\n",
      "Epoch: 0, Loss = 0.6907756022371042\n",
      "Epoch: 0, Loss = 0.6907756021827649\n",
      "Epoch: 0, Loss = 0.6907756015232631\n",
      "Epoch: 0, Loss = 0.6907756014715267\n",
      "Epoch: 0, Loss = 0.6907756014201167\n",
      "Epoch: 0, Loss = 0.69077560136903\n",
      "Epoch: 0, Loss = 0.6907756007203488\n",
      "Epoch: 0, Loss = 0.6907756000757217\n",
      "Epoch: 0, Loss = 0.690775599435111\n",
      "Epoch: 0, Loss = 0.6907755993908237\n",
      "Epoch: 0, Loss = 0.6907755993468104\n",
      "Epoch: 0, Loss = 0.690775599303069\n",
      "Epoch: 0, Loss = 0.6907755992595966\n",
      "Epoch: 0, Loss = 0.6907755986313147\n",
      "Epoch: 0, Loss = 0.6907755980068755\n",
      "Epoch: 0, Loss = 0.6907755973862438\n",
      "Epoch: 0, Loss = 0.690775596769385\n",
      "Epoch: 0, Loss = 0.6907755961562648\n",
      "Epoch: 0, Loss = 0.6907755961230875\n",
      "Epoch: 0, Loss = 0.69077559609011\n",
      "Epoch: 0, Loss = 0.6907755954845531\n",
      "Epoch: 0, Loss = 0.6907755954536849\n",
      "Epoch: 0, Loss = 0.6907755954230009\n",
      "Epoch: 0, Loss = 0.6907755953924997\n",
      "Epoch: 0, Loss = 0.6907755947962005\n",
      "Epoch: 0, Loss = 0.6907755942034298\n",
      "Epoch: 0, Loss = 0.6907755936141563\n",
      "Epoch: 0, Loss = 0.690775593028349\n",
      "Epoch: 0, Loss = 0.6907755930053174\n",
      "Epoch: 0, Loss = 0.6907755929824204\n",
      "Epoch: 0, Loss = 0.690775592959657\n",
      "Epoch: 0, Loss = 0.690775592937026\n",
      "Epoch: 0, Loss = 0.6907755927763124\n",
      "Epoch: 0, Loss = 0.6907755926165278\n",
      "Epoch: 0, Loss = 0.6907755925950811\n",
      "Epoch: 0, Loss = 0.6907755925737579\n",
      "Epoch: 0, Loss = 0.6907755925525567\n",
      "Epoch: 0, Loss = 0.6907755925314767\n",
      "Epoch: 0, Loss = 0.6907755925105168\n",
      "Epoch: 0, Loss = 0.690775592489676\n",
      "Epoch: 0, Loss = 0.6907755924689534\n",
      "Epoch: 0, Loss = 0.6907755920442484\n",
      "Epoch: 0, Loss = 0.6907755918905769\n",
      "Epoch: 0, Loss = 0.6907755918717117\n",
      "Epoch: 0, Loss = 0.6907755914522486\n",
      "Epoch: 0, Loss = 0.6907755909019342\n",
      "Epoch: 0, Loss = 0.6907755903546856\n",
      "Epoch: 0, Loss = 0.6907755903402965\n",
      "Epoch: 0, Loss = 0.6907755905901626\n",
      "Epoch: 0, Loss = 0.6907755905752024\n",
      "Epoch: 0, Loss = 0.6907755905603246\n",
      "Epoch: 0, Loss = 0.6907755900215317\n",
      "Epoch: 0, Loss = 0.6907755894856911\n",
      "Epoch: 0, Loss = 0.6907755889527785\n",
      "Epoch: 0, Loss = 0.6907755888125552\n",
      "Epoch: 0, Loss = 0.6907755888026693\n",
      "Epoch: 0, Loss = 0.6907755887928371\n",
      "Epoch: 0, Loss = 0.6907755886541831\n",
      "Epoch: 0, Loss = 0.690775588644804\n",
      "Epoch: 0, Loss = 0.6907755885072934\n",
      "Epoch: 0, Loss = 0.6907755884983584\n",
      "Epoch: 0, Loss = 0.6907755883619747\n",
      "Epoch: 0, Loss = 0.690775588353475\n",
      "Epoch: 0, Loss = 0.6907755883450204\n",
      "Epoch: 0, Loss = 0.6907755883366107\n",
      "Epoch: 0, Loss = 0.6907755883282455\n",
      "Epoch: 0, Loss = 0.6907755881941098\n",
      "Epoch: 0, Loss = 0.6907755876842298\n",
      "Epoch: 0, Loss = 0.6907755871770263\n",
      "Epoch: 0, Loss = 0.6907755866724783\n",
      "Epoch: 0, Loss = 0.6907755862950656\n",
      "Epoch: 0, Loss = 0.6907755857954423\n",
      "Epoch: 0, Loss = 0.6907755854222681\n",
      "Epoch: 0, Loss = 0.6907755854216264\n",
      "Epoch: 0, Loss = 0.6907755856674155\n",
      "Epoch: 0, Loss = 0.6907755856661453\n",
      "Epoch: 0, Loss = 0.6907755855423013\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755851745605\n",
      "Epoch: 0, Loss = 0.6907755846929069\n",
      "Epoch: 0, Loss = 0.6907755842136796\n",
      "Epoch: 0, Loss = 0.6907755837368605\n",
      "Epoch: 0, Loss = 0.6907755833819397\n",
      "Epoch: 0, Loss = 0.6907755830287934\n",
      "Epoch: 0, Loss = 0.6907755825584964\n",
      "Epoch: 0, Loss = 0.6907755825650039\n",
      "Epoch: 0, Loss = 0.6907755820981918\n",
      "Epoch: 0, Loss = 0.6907755816336906\n",
      "Epoch: 0, Loss = 0.6907755811714832\n",
      "Epoch: 0, Loss = 0.6907755807115527\n",
      "Epoch: 0, Loss = 0.6907755803710413\n",
      "Epoch: 0, Loss = 0.6907755803828146\n",
      "Epoch: 0, Loss = 0.6907755803945304\n",
      "Epoch: 0, Loss = 0.6907755804061889\n",
      "Epoch: 0, Loss = 0.6907755799537157\n",
      "Epoch: 0, Loss = 0.690775579503439\n",
      "Epoch: 0, Loss = 0.6907755795171705\n",
      "Epoch: 0, Loss = 0.6907755795308357\n",
      "Epoch: 0, Loss = 0.690775579544435\n",
      "Epoch: 0, Loss = 0.690775579214096\n",
      "Loss after Epoch 0: 0.007199238418794208\n",
      "Finish training for 1 epochs\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
