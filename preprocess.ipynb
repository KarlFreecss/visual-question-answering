{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import socket\n",
    "import getpass\n",
    "import nntools as nt\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/datasets/ee285f-public/VQA2017/'\n",
    "q_dir = '/datasets/ee285f-public/VQA2017/v2_OpenEnded_mscoco_'\n",
    "ans_dir = '/datasets/ee285f-public/VQA2017/v2_mscoco_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entire cell uses code found: https://github.com/zcyang/imageqa-san/blob/master/data_vqa/process_function.py\n",
    "def process_sentence(sentence):\n",
    "    periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
    "    commaStrip   = re.compile(\"(\\d)(\\,)(\\d)\")\n",
    "    punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
    "                    '(', ')', '=', '+', '\\\\', '_', '-',\n",
    "                    '>', '<', '@', '`', ',', '?', '!']\n",
    "    contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\", \\\n",
    "                    \"couldn'tve\": \"couldn't've\", \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\": \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \\\n",
    "                    \"hadnt've\": \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\": \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \\\n",
    "                    \"he'dve\": \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\", \"hows\": \"how's\", \"id've\": \"i'd've\", \"i'dve\": \"i'd've\", \\\n",
    "                    \"im\": \"i'm\", \"ive\": \"i've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\": \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\", \\\n",
    "                    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\": \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\", \\\n",
    "                    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\", \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\", \\\n",
    "                    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\": \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\": \"she'd've\", \\\n",
    "                    \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\": \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\": \"shouldn't've\", \\\n",
    "                    \"somebody'd\": \"somebodyd\", \"somebodyd've\": \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\": \"somebody'll\", \\\n",
    "                    \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\", \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\", \\\n",
    "                    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\": \"something'd\", \"somethingd've\": \"something'd've\", \\\n",
    "                    \"something'dve\": \"something'd've\", \"somethingll\": \"something'll\", \"thats\": \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\", \\\n",
    "                    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\": \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \\\n",
    "                    \"they'dve\": \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\": \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \\\n",
    "                    \"wed've\": \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\": \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \\\n",
    "                    \"whats\": \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\": \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\", \\\n",
    "                    \"whod\": \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\": \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\", \\\n",
    "                    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\": \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\", \\\n",
    "                    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\": \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\", \\\n",
    "                    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\": \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \\\n",
    "                    \"youll\": \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"}\n",
    "\n",
    "    inText = sentence.replace('\\n', ' ')\n",
    "    inText = inText.replace('\\t', ' ')\n",
    "    inText = inText.strip()\n",
    "    \n",
    "    outText = inText\n",
    "    for p in punct:\n",
    "        if (p + ' ' in inText or ' ' + p in inText) or \\\n",
    "           (re.search(commaStrip, inText) != None):\n",
    "            outText = outText.replace(p, '')\n",
    "        else:\n",
    "            outText = outText.replace(p, ' ')\n",
    "            \n",
    "    outText = periodStrip.sub(\"\", outText, re.UNICODE)\n",
    "    outText = outText.lower().split()\n",
    "    for wordId, word in enumerate(outText):\n",
    "        if word in contractions:            \n",
    "            outText[wordId] = contractions[word]\n",
    "    outText = ' '.join(outText)\n",
    "    \n",
    "    return outText\n",
    "\n",
    "def process_answer(answer):\n",
    "    articles = ['a', 'an', 'the']\n",
    "    manualMap = { 'none': '0', 'zero': '0', 'one': '1', 'two': '2', 'three':\n",
    "                  '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7',\n",
    "                  'eight': '8', 'nine': '9', 'ten': '10' }\n",
    "    new_answer = process_sentence(answer)\n",
    "    outText = []\n",
    "    for word in new_answer.split():\n",
    "        if word not in articles:\n",
    "            word = manualMap.setdefault(word, word)\n",
    "            outText.append(word)\n",
    "    return ' '.join(outText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimshow(image, ax=plt):\n",
    "    ax.figure()\n",
    "    image = image.to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image < 0] = 0\n",
    "    image[image > 1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCOCODataset(td.Dataset):\n",
    "    def __init__(self, images_dir, q_dir, ans_dir, mode='train', image_size=(448, 448)):\n",
    "        super(MSCOCODataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        self.root_image = os.path.join(images_dir, \"%s2014\" % mode)\n",
    "        self.qa_dict = defaultdict(list)\n",
    "        \n",
    "        root_q = os.path.join(q_dir + \"%s2014_questions.json\" % mode)\n",
    "        root_ans = os.path.join(ans_dir + \"%s2014_annotations.json\" % mode)\n",
    "        \n",
    "        with open(root_q) as f:\n",
    "            questions = json.load(f)['questions']\n",
    "        \n",
    "        with open(root_ans) as f:\n",
    "            answers = json.load(f)['annotations']\n",
    "        \n",
    "        for q, a in zip(questions, answers):\n",
    "            img_id = str(q['image_id'])\n",
    "                                    \n",
    "            self.qa_dict[img_id].append((process_sentence(q['question']),\n",
    "                                    process_answer(a['multiple_choice_answer'])))\n",
    "        \n",
    "        self.qa_list = list(self.qa_dict.items())\n",
    "        \n",
    "        self.vocab_q = self.create_vocab()\n",
    "        self.vocab_a = self.get_top_answers(1000)\n",
    "\n",
    "    def create_vocab(self):\n",
    "        #get all questions from dataloader\n",
    "        questions = []\n",
    "\n",
    "        for data in self.qa_list: \n",
    "            for qa in data[1]:\n",
    "                questions.append(qa[0])\n",
    "        vocab = {}\n",
    "        counter = 0 \n",
    "        for question in questions:\n",
    "            for word in question.split(\" \"):\n",
    "                if word not in vocab: \n",
    "                    vocab[word] = counter\n",
    "                    counter = counter + 1\n",
    "        return vocab\n",
    "    \n",
    "    def get_top_answers(self, top_num):\n",
    "        ans_count = defaultdict(int)\n",
    "        \n",
    "        for entry in self.qa_list: \n",
    "            for qa in entry[1]:\n",
    "                ans_count[qa[1]] += 1\n",
    "\n",
    "        ans_count = sorted(ans_count.items(), key=lambda x : x[1], reverse=True)\n",
    "        \n",
    "        ans = {ans_count[i][0] : i for i in range(top_num)}\n",
    "        \n",
    "        return ans\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"MSCOCODataset(mode={}, image_size={})\" . \\\n",
    "                format(self.mode, self.image_size)\n",
    "\n",
    "    def one_hot_code(self, inp, mapping):\n",
    "        vecs = len(inp)*[torch.zeros(len(mapping)),]\n",
    "        \n",
    "        for i, each in enumerate(inp):            \n",
    "            for word in each.split(\" \"):\n",
    "                if word in mapping: \n",
    "                    vecs[i][mapping[word]] += 1\n",
    "                        \n",
    "        return vecs\n",
    "                        \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.qa_list[idx]\n",
    "        img_id = entry[0]\n",
    "        qa = entry[1]\n",
    " \n",
    "        img_path = os.path.join(self.root_image, \"COCO_%s2014_%s.jpg\" % (self.mode, img_id.zfill(12)))\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        transform = tv.transforms.Compose([tv.transforms.Resize(self.image_size),\n",
    "                                           tv.transforms.ToTensor(),\n",
    "                                           tv.transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                                   (0.5, 0.5, 0.5))])\n",
    "        x = transform(img)\n",
    "        \n",
    "        one_hot_q = self.one_hot_code([each[0] for each in qa], self.vocab_q)\n",
    "        one_hot_ans = self.one_hot_code([each[1] for each in qa], self.vocab_a)\n",
    "        \n",
    "        return x, qa, list(zip(one_hot_q, one_hot_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MSCOCODataset(images_dir, q_dir, ans_dir, mode='train', image_size=(448, 448))\n",
    "val = MSCOCODataset(images_dir, q_dir, ans_dir, mode=\"val\", image_size=(448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
