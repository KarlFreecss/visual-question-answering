{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%run preprocess.ipynb\n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import nntools as nt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validation(model, dataloader, lr=0.01, rho=0.9, mode='training'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    running_loss, running_accuracy, num_updates = 0.0, 0.0, 0.0\n",
    "    model.train() \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=rho)\n",
    "    \n",
    "    # Iterate over data.\n",
    "    for image, question, answer in dataloader:\n",
    "        if (device == 'cuda'):\n",
    "            image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
    "\n",
    "        image, question, answer = Variable(image), Variable(question), Variable(answer)\n",
    "\n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "        predicted_answer = model(image, question)\n",
    "        \n",
    "\n",
    "        answer = answer.squeeze().transpose(0, 1)\n",
    "        predicted_answer = predicted_answer.squeeze().transpose(0,1)\n",
    "        _, y_pred = torch.max(predicted_answer, 1)\n",
    "        _, class_indices = torch.max(answer, 1)        \n",
    "\n",
    "        answer = torch.tensor(answer, dtype=torch.long, device=device)\n",
    "        \n",
    "        loss = criterion(predicted_answer, class_indices)\n",
    "        print(loss.item())\n",
    "        \n",
    "        if(mode=='training'):\n",
    "            # backward + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        with torch.no_grad():\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += torch.sum((y_pred == class_indices).data)\n",
    "    \n",
    "        num_updates += 1\n",
    "\n",
    "    loss = running_loss / num_updates\n",
    "    acc = (running_accuracy / len(dataloader.dataset)) * 100\n",
    "    print('Train Loss: {:.4f} Acc: {:2.3f} ({}/{})'.format(loss, acc, running_accuracy, num_updates))\n",
    "    \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, save_dir, num_epochs=25, best_accuracy=0, start_epoch=0):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = best_accuracy\n",
    "    \n",
    "    training_loss_history = []\n",
    "    training_accuracy_history = []\n",
    "\n",
    "    validation_loss_history = []\n",
    "    validation_accuracy_history = []\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_begin = time.time()\n",
    "        train_loss, train_acc = train_and_validation(model, train_loader, mode='training') \n",
    "        training_loss_history.append(train_loss)\n",
    "        training_accuracy_history.append(train_acc)    \n",
    "        print('Epoch= ' + str(epoch) + ' Train Loss= ' + str(train_loss))\n",
    "\n",
    "        validation_begin = time.time()\n",
    "        val_loss, val_acc = train_and_validation(model, train_loader, mode='validation')\n",
    "        validation_loss_history.append(train_loss)\n",
    "        validation_accuracy_history.append(train_acc)  \n",
    "        print('Epoch= ' + str(epoch) + ' Validation Loss= ' + str(train_loss))\n",
    "\n",
    "        # deep copy the model\n",
    "        is_best = val_acc > best_acc\n",
    "        if is_best:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        save_checkpoint(save_dir, {\n",
    "            'epoch': epoch,\n",
    "            'best_acc': best_acc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'training_history': [training_loss_history, training_accuracy_history],\n",
    "            'validation_history': [validation_loss_history, validation_accuracy_history]\n",
    "        }, is_best)\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_dir, state, is_best):\n",
    "    savepath = save_dir + '/' + 'checkpoint.pth.tar'\n",
    "    torch.save(state, savepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(savepath, save_dir + '/' + 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(train))\n",
    "train_ind = indices[:int(len(train)*0.8)]\n",
    "val_ind = indices[int(len(train)*0.8):]\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\n",
    "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=10, pin_memory=True, sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train, batch_size=10, pin_memory=True, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb\n",
    "san = SAN(num_classes=1000, batch_size=10, vocab_size=len(train.vocab_q), embedding_dim=1000,\n",
    "          output_vgg=1024, input_attention=1024, output_attention=512)\n",
    "san = san.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 1000])\n",
      "torch.Size([10, 1])\n",
      "tensor([[674],\n",
      "        [517],\n",
      "        [954],\n",
      "        [ 56],\n",
      "        [743],\n",
      "        [ 78],\n",
      "        [143],\n",
      "        [185],\n",
      "        [171],\n",
      "        [ 47]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader: \n",
    "    y = san(i[0].to('cuda'),i[1].to('cuda'))\n",
    "    break\n",
    "print(y.shape)\n",
    "_, y_pred = torch.max(y, 2)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.409224987030029\n",
      "6.999348163604736\n",
      "6.444126129150391\n",
      "6.424279689788818\n",
      "5.944341659545898\n",
      "6.297928333282471\n",
      "6.364412307739258\n",
      "6.029438018798828\n",
      "6.444243431091309\n",
      "5.758861541748047\n",
      "7.448818206787109\n",
      "5.716835021972656\n",
      "5.683062553405762\n",
      "6.019190311431885\n",
      "5.53284215927124\n",
      "6.581063747406006\n",
      "6.639585018157959\n",
      "6.936239719390869\n",
      "6.322841167449951\n",
      "6.184286594390869\n",
      "6.697512626647949\n",
      "6.6117987632751465\n",
      "6.448841094970703\n",
      "6.53084659576416\n",
      "6.412446022033691\n",
      "7.214198112487793\n",
      "7.837355136871338\n",
      "8.112953186035156\n",
      "7.638538837432861\n",
      "8.678786277770996\n",
      "7.842965602874756\n",
      "9.308819770812988\n",
      "7.269656658172607\n",
      "7.902585983276367\n",
      "9.852928161621094\n",
      "9.378305435180664\n",
      "10.131352424621582\n",
      "11.932426452636719\n",
      "10.703460693359375\n",
      "9.725846290588379\n",
      "10.950457572937012\n",
      "14.05360221862793\n",
      "17.588022232055664\n",
      "13.436834335327148\n",
      "13.856095314025879\n",
      "17.214458465576172\n",
      "16.363698959350586\n",
      "14.676942825317383\n",
      "14.202319145202637\n",
      "13.759724617004395\n",
      "15.607967376708984\n",
      "17.28377342224121\n",
      "16.198196411132812\n",
      "24.730485916137695\n",
      "16.8532772064209\n",
      "21.10552215576172\n",
      "19.058109283447266\n",
      "19.574085235595703\n",
      "12.352806091308594\n",
      "20.016502380371094\n",
      "22.479310989379883\n",
      "9.55919075012207\n",
      "17.215911865234375\n",
      "24.45656394958496\n",
      "13.391145706176758\n",
      "20.65110206604004\n",
      "23.892108917236328\n",
      "28.121179580688477\n",
      "28.85275650024414\n",
      "18.622968673706055\n",
      "31.80990982055664\n",
      "19.50031852722168\n",
      "19.775821685791016\n",
      "29.911823272705078\n",
      "32.14361572265625\n",
      "12.289223670959473\n",
      "5.701248645782471\n",
      "25.32314682006836\n",
      "21.829631805419922\n",
      "29.84380531311035\n",
      "45.51393508911133\n",
      "22.857397079467773\n",
      "47.600006103515625\n",
      "48.05819320678711\n",
      "45.568599700927734\n",
      "37.266971588134766\n",
      "55.13495635986328\n",
      "11.951007843017578\n",
      "77.2164306640625\n",
      "37.12449645996094\n",
      "35.46323013305664\n",
      "54.69599914550781\n",
      "18.289602279663086\n",
      "36.74911117553711\n",
      "12.283935546875\n",
      "58.10127639770508\n",
      "22.764537811279297\n",
      "20.487321853637695\n",
      "34.43642044067383\n",
      "55.899559020996094\n",
      "125.6479263305664\n",
      "25.568500518798828\n",
      "23.128040313720703\n",
      "60.911006927490234\n",
      "70.42325592041016\n",
      "93.918212890625\n",
      "12.34140682220459\n",
      "26.940879821777344\n",
      "78.59849548339844\n",
      "60.538185119628906\n",
      "32.688228607177734\n",
      "44.7446403503418\n",
      "74.50787353515625\n",
      "8.445323944091797\n",
      "101.33358001708984\n",
      "56.60301208496094\n",
      "107.36734008789062\n",
      "27.846433639526367\n",
      "72.92828369140625\n",
      "24.518234252929688\n",
      "51.418636322021484\n",
      "65.64585876464844\n",
      "37.284080505371094\n",
      "69.62533569335938\n",
      "50.93310546875\n",
      "50.34504699707031\n",
      "66.8740463256836\n",
      "6.069828033447266\n",
      "46.61623001098633\n",
      "101.24464416503906\n",
      "131.34304809570312\n",
      "22.714893341064453\n",
      "71.14818572998047\n",
      "43.01222610473633\n",
      "94.6838607788086\n",
      "39.221290588378906\n",
      "33.73846435546875\n",
      "38.23826217651367\n",
      "75.36288452148438\n",
      "74.16565704345703\n",
      "57.23435592651367\n",
      "82.1609878540039\n",
      "83.89640808105469\n",
      "41.459510803222656\n",
      "86.9055404663086\n",
      "81.46328735351562\n",
      "118.33228302001953\n",
      "52.45707321166992\n",
      "46.151363372802734\n",
      "64.0354995727539\n",
      "28.545812606811523\n",
      "63.89556121826172\n",
      "49.30380630493164\n",
      "40.389644622802734\n",
      "29.925716400146484\n",
      "24.38726806640625\n",
      "60.944664001464844\n",
      "56.13724136352539\n",
      "64.44497680664062\n",
      "96.2940444946289\n",
      "129.70188903808594\n",
      "9.264124870300293\n",
      "59.03527069091797\n",
      "59.14385986328125\n",
      "38.38715362548828\n",
      "47.889888763427734\n",
      "87.14291381835938\n",
      "64.83628845214844\n",
      "25.455768585205078\n",
      "104.10248565673828\n",
      "79.37572479248047\n",
      "26.81757164001465\n",
      "20.45867919921875\n",
      "60.83600616455078\n",
      "41.9412727355957\n",
      "48.04729461669922\n",
      "74.07320404052734\n",
      "27.00814437866211\n",
      "71.12274932861328\n",
      "20.723522186279297\n",
      "77.46585845947266\n",
      "36.84577941894531\n",
      "26.397260665893555\n",
      "50.27336502075195\n",
      "59.92744445800781\n",
      "53.464324951171875\n",
      "72.81002044677734\n",
      "27.792715072631836\n",
      "79.93892669677734\n",
      "113.65084075927734\n",
      "210.02467346191406\n",
      "96.81149291992188\n",
      "71.05672454833984\n",
      "55.95764923095703\n",
      "46.65459060668945\n",
      "7.107672214508057\n",
      "146.79725646972656\n",
      "65.63433837890625\n",
      "84.33768463134766\n",
      "84.01830291748047\n",
      "43.01630401611328\n",
      "71.27970123291016\n",
      "26.247373580932617\n",
      "54.2254638671875\n",
      "68.27452850341797\n",
      "113.68748474121094\n",
      "40.025753021240234\n",
      "38.09934616088867\n",
      "64.37317657470703\n",
      "43.1146240234375\n",
      "5.077847003936768\n",
      "60.06704330444336\n",
      "48.92018508911133\n",
      "125.32498931884766\n",
      "35.326087951660156\n",
      "57.38182830810547\n",
      "68.72724914550781\n",
      "119.88867950439453\n",
      "108.13175964355469\n",
      "67.73897552490234\n",
      "94.88957214355469\n",
      "36.842411041259766\n",
      "53.35597229003906\n",
      "41.6407356262207\n",
      "53.67546844482422\n",
      "62.419864654541016\n",
      "123.00592041015625\n",
      "74.45147705078125\n",
      "25.981664657592773\n",
      "97.94446563720703\n",
      "44.83723831176758\n",
      "42.082706451416016\n",
      "105.78917694091797\n",
      "29.68608856201172\n",
      "65.67095947265625\n",
      "18.036712646484375\n",
      "3.9401161670684814\n",
      "44.35795974731445\n",
      "62.93686294555664\n",
      "41.49702835083008\n",
      "19.539602279663086\n",
      "55.62112808227539\n",
      "91.19055938720703\n",
      "36.459083557128906\n",
      "75.73889923095703\n",
      "47.34879684448242\n",
      "39.983863830566406\n",
      "27.54741859436035\n",
      "79.28111267089844\n",
      "132.5254669189453\n",
      "68.0440673828125\n",
      "30.245826721191406\n",
      "111.988037109375\n",
      "11.721186637878418\n",
      "43.36055374145508\n",
      "5.635159015655518\n",
      "5.8224053382873535\n",
      "91.70775604248047\n",
      "110.08323669433594\n",
      "83.6896743774414\n",
      "64.16539001464844\n",
      "51.153892517089844\n",
      "83.75726318359375\n",
      "55.76963806152344\n",
      "119.35743713378906\n",
      "50.56480026245117\n",
      "14.341998100280762\n",
      "28.592350006103516\n",
      "83.50035095214844\n",
      "72.68207550048828\n",
      "79.33296203613281\n",
      "68.65076446533203\n",
      "6.3206682205200195\n",
      "74.108642578125\n",
      "22.314529418945312\n",
      "84.73744201660156\n",
      "46.50458526611328\n",
      "46.860809326171875\n",
      "33.78856658935547\n",
      "96.20513153076172\n",
      "39.68376922607422\n",
      "90.41332244873047\n",
      "49.801841735839844\n",
      "75.32371520996094\n",
      "41.592613220214844\n",
      "12.112709045410156\n",
      "41.338958740234375\n",
      "36.84581756591797\n",
      "54.31113052368164\n",
      "93.10804748535156\n",
      "47.1146354675293\n",
      "32.89320373535156\n",
      "11.082674980163574\n",
      "96.80106353759766\n",
      "63.670501708984375\n",
      "90.08710479736328\n",
      "131.15171813964844\n",
      "9.805747032165527\n",
      "55.28456497192383\n",
      "95.5791015625\n",
      "107.60620880126953\n",
      "63.92961502075195\n",
      "78.89436340332031\n",
      "102.27898406982422\n",
      "39.017852783203125\n",
      "43.823577880859375\n",
      "59.089229583740234\n",
      "88.40425109863281\n",
      "64.97860717773438\n",
      "8.85595703125\n",
      "46.33372116088867\n",
      "93.5979232788086\n",
      "29.009563446044922\n",
      "76.19652557373047\n",
      "69.6787338256836\n",
      "33.99660873413086\n",
      "69.67574310302734\n",
      "82.32916259765625\n",
      "21.585933685302734\n",
      "71.9964828491211\n",
      "72.7219009399414\n",
      "108.62694549560547\n",
      "32.59024429321289\n",
      "52.767005920410156\n",
      "82.89014434814453\n",
      "106.2691879272461\n",
      "10.321466445922852\n",
      "90.32447052001953\n",
      "87.8631820678711\n",
      "43.87127685546875\n",
      "91.460205078125\n",
      "50.88705062866211\n",
      "43.75337600708008\n",
      "51.36064147949219\n",
      "57.03029251098633\n",
      "134.0238037109375\n",
      "5.449260711669922\n",
      "50.054466247558594\n",
      "28.263273239135742\n",
      "22.45248794555664\n",
      "66.69522094726562\n",
      "33.79814529418945\n",
      "37.482139587402344\n",
      "61.05514907836914\n",
      "39.077308654785156\n",
      "40.68446731567383\n",
      "90.95563507080078\n",
      "135.88064575195312\n",
      "71.84852600097656\n",
      "70.31842803955078\n",
      "120.87499237060547\n",
      "28.69754409790039\n",
      "83.14539337158203\n",
      "131.05747985839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.40434265136719\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-211-7ed13cd64066>\", line 1, in <module>\n",
      "    train_model(san, train_loader, val_loader, 'test', num_epochs=1, best_accuracy=0, start_epoch=0)\n",
      "  File \"<ipython-input-205-b7708ecb0f9c>\", line 16, in train_model\n",
      "    train_loss, train_acc = train_and_validation(model, train_loader, mode='training')\n",
      "  File \"<ipython-input-204-61a92009b27e>\", line 11, in train_and_validation\n",
      "    for image, question, answer in dataloader:\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 615, in __next__\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 615, in <listcomp>\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"<ipython-input-1-4efd2df9a848>\", line 89, in __getitem__\n",
      "    img = Image.open(img_path).convert(\"RGB\")\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/PIL/Image.py\", line 915, in convert\n",
      "    self.load()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\", line 198, in load\n",
      "    self.load_prepare()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\", line 268, in load_prepare\n",
      "    self.im = Image.core.new(self.mode, self.size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_model(san, train_loader, val_loader, 'test', num_epochs=1, best_accuracy=0, start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
